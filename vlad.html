<!DOCTYPE HTML>
<html>
<head>
<link rel="stylesheet" href='style.css'>
<title>vlad descriptors</title>
</head>
<body>
<div class=content>
  <h2>vlad descriptors</h2>
  an improvement on <a href="https://gilscvblog.com/2013/08/23/bag-of-words-models-for-visual-categorization/">BagOfWords</a> descriptors; <br>
  instead of increasing histogram bins for matching features / codewords: <br><p>
  <img src="https://gilscvblog.files.wordpress.com/2013/08/figure41.jpg"></img><br><p>
  we calculate the residual (the difference, 1st order moment) between the (SIFT or SURF) descriptor and it's closest dictionary entry:<p>
  <img src="http://www.svcl.ucsd.edu/projects/attdyn/image/encoding.png" width=576 height=437></img><br><p>
  and add them up (per dictionary entry). after extensive normalization, we get a feature in  the same size of the dictionary.<p>
  the upside of it is this:<br>
  only very coarse (kmeans) clustering is needed for this, like K=64 will do.<br>
  (while you need a significantly large K for BoW (i've seen like 20k used), to get hold of the really <i>relevant</i> cluster centers)
  <script src="https://gist.github.com/berak/2ef9f4f64ec387f2949b18899f44491c.js"> </script>
</div>
<div class="nav">
<a href="transfer.html"> transfer learning </a><br>
<a href="vlad.html"> vlad descriptors </a><br>
<a href="one_shot.html"> one shot similarity </a><br>
<a href="profile.html"> profiling opencv </a><br>
<a href="pico.html"> webbrowser face detection </a><br>
<a href="pose.html"> openpose models </a><br>
<a href="printnet.html"> dnn print net </a><br>
<a href="prolog.html"> owl positive </a><br>
<a href="music.html"> music ! </a><br>
<a href="photo-stereo.html"> photometric stereo </a><br>
<a href="lfw.html"> lfw mean stddev </a><br>
</div>
</body>
</html>
